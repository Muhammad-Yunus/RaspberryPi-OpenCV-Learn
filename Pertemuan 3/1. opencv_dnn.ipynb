{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning in OpenCV\n",
    "\n",
    "### 1. Machine Learning vs Deep Learning\n",
    "*Machine learning and deep learning are both types of AI. In short, **machine learning** is AI that can automatically adapt with minimal human interference. **Deep learning** is a subset of machine learning that uses artificial **neural networks** to mimic the learning process of the human brain.* — [coursera.org](https://www.coursera.org/articles/ai-vs-deep-learning-vs-machine-learning-beginners-guide)<br><br>\n",
    "<img src=\"resource/ml.png\" style=\"width:500px\"></img><br><br>\n",
    "\n",
    "- Table comparison :\n",
    "<table><thead><tr><th><strong>Machine learning</strong></th><th><strong>Deep learning</strong></th></tr></thead><tbody><tr><td>A subset of AI</td><td>A subset of machine learning</td></tr><tr><td>Can train on smaller data sets</td><td>Requires large amounts of data</td></tr><tr><td>Requires more human intervention to correct and learn</td><td>Learns on its own from environment and past mistakes</td></tr><tr><td>Shorter training and lower accuracy</td><td>Longer training and higher accuracy</td></tr><tr><td>Makes simple, linear correlations</td><td>Makes non-linear, complex correlations</td></tr><tr><td>Can train on a CPU (central processing unit)</td><td>Needs a specialized GPU (graphics processing unit) to train</td></tr></tbody></table><br><br>\n",
    "\n",
    "- Inference/Forward Pass comparison :<br>\n",
    "<img src=\"resource/ml-dl.png\" style=\"width:700px;background:white\"></img><br>\n",
    "    - **ML** memisahkan bagian **Feature Extraction** dengan bagian **Classification/Detection/Prediction**.\n",
    "    - **DL** menggabungkan bagian **Feature Extraction** dengan bagian **Classification/Detection/Prediction** dalam satu model. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pelajari Selengkapnya terkait ML vs DL :\n",
    "\n",
    "    - [“#1 Pengenalan Machine Learning”](https://medium.com/@yunusmuhammad007/pengenalan-machine-learning-2320b5ca7266)\n",
    "    - [“#2 Supervised VS Unsupervised VS Reinforcement ML”](https://link.medium.com/wEcGRj3gq5)\n",
    "    - [“#3 Machine Learning Evaluation”](https://link.medium.com/qJ9Kd26gq5)\n",
    "    - [“#4 Alat dan Bahan untuk Machine Learning”](https://medium.com/@yunusmuhammad007/3-alat-dan-bahan-untuk-machine-learning-92c717286624)\n",
    "    - [“#5 Basic Python Programming”](https://medium.com/@yunusmuhammad007/5-basic-python-programming-87c89e1d0d3e)\n",
    "    - [“#6 Artificial Neural Network (ANN) — Part 1 (Pengenalan)”](https://link.medium.com/TbaRUcJZv5)\n",
    "    - [“#7 Artificial Neural Network (ANN) — Part 2 (Single Layer Perceptron)”](https://link.medium.com/kpBiXHBdz5)\n",
    "    - [“#8 Artificial Neural Network (ANN) — Part 3 (Teori Dasar Multi Layer Perceptron Backpropagation)”](https://link.medium.com/D7rAjn69F6)\n",
    "    - [“#9 Artificial Neural Network (ANN) — Part 4 (MLP Backpropagation Time Series Forecasting…”](https://link.medium.com/s2ZZFy89F6)\n",
    "    - [“#10 Artificial Neural Network (ANN) — Part 5 (Time Series Forecasting ISPU CO DKI Jakarta…”](https://link.medium.com/ccHKkBaaG6)\n",
    "    - [“#11 Artificial Neural Network (ANN) — Part 6 Konsep Dasar Convolutional Neural Network (CNN)”](https://link.medium.com/gy2J4beaG6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training vs Inferencing Deep Learning Model\n",
    "\n",
    "- **Training** memerlukan **dataset** dan akan menghasilkan **Model**.\n",
    "- **Inference** memerlukan **Model** dan **data test** yang akan menghasilkan **Prediction**.  \n",
    "<img src=\"resource/training-inferencing.jpg\" style=\"width:700px\"></img><br><br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. How to Training Deep Learing Model\n",
    "\n",
    "- Untuk mentraining Model Deep Learning bisa menggunakan **Framework Deep Learning** yang sudah standard, seperti :\n",
    "    - [Tensorflow](https://www.tensorflow.org/)\n",
    "    - [Keras](https://keras.io/)\n",
    "    - [MXNet](https://mxnet.apache.org/)\n",
    "    - [Caffe](https://caffe.berkeleyvision.org/)\n",
    "    - [H2O](https://h2o.ai/)\n",
    "    - [Darknet](https://github.com/pjreddie/darknet)\n",
    "    - [Torch](https://pytorch.org/)\n",
    "<br><br>\n",
    "- Pelajari Selengkapnya terkait **Training Model Deep Learning** :\n",
    "    - [[Notebook] Intro to Neural Network with Keras](https://www.youtube.com/watch?v=Vt8oYlwHYIE&t=3047s)\n",
    "    - [[Video] Training Model Face Recognition with Keras](https://www.youtube.com/watch?v=m0OWRRGYZx8&t=2021s)\n",
    "    - [[Notebook] Training Model Face Recognition with Keras](https://github.com/Muhammad-Yunus/Materi-Training/blob/main/C.%20Facerecognition/pertemuan_7/2.%20Implementasi%20Neural%20Network.ipynb)\n",
    "    - [[Notebook] Intro to Object Detection with Tensorflow](https://github.com/Muhammad-Yunus/Jetson-Nano-Object-Detection-Learn/tree/main/pertemuan_2)\n",
    "    - [[Video] Training Model Object Detection with Tensorflow](https://www.youtube.com/watch?v=utRrw1TJG-U&t=3808s)\n",
    "    - [[Notebook] Training Model Object Detection with Tensorflow](https://github.com/Muhammad-Yunus/Jetson-Nano-Object-Detection-Learn/tree/main/pertemuan_3)\n",
    "    - [[Video] Intro & Training Yolo Model Object Detection with Darknet](https://www.youtube.com/watch?v=kb2nsM8EN0M&t=42s)\n",
    "    - [[Notebook] Intro & Training Yolo Model Object Detection with Darknet](https://github.com/Muhammad-Yunus/Jetson-Nano-Object-Detection-Learn/tree/main/pertemuan_4)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dimana kita dapat mendownload model yang sudah di training?\n",
    "    - [OpenCV Zoo](https://github.com/opencv/opencv_zoo)\n",
    "    - [https://modelzoo.co/](https://modelzoo.co/)\n",
    "    - [TensorFlow Model Zoo](https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md)\n",
    "    - [ONNX Model Zoo](https://github.com/onnx/models)\n",
    "    - [Darknet Yolo](https://pjreddie.com/darknet/yolo/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. OpenCV DNN\n",
    "\n",
    "**OpenCV DNN - Deep Neural Network** adalah library untuk **Inference** atau **Forward Pass** Model Deep Learning dari beragam framework populer. Menyediakan struktur prrogram yang sederhana dan high performance (mensupport beragam CPU,GPU dan Inference Engine).\n",
    "- Compatibility : > OpenCV 3.3\n",
    "- Wiki : https://github.com/opencv/opencv/wiki/Deep-Learning-in-OpenCV\n",
    "- The supported frameworks:\n",
    "    - Caffe\n",
    "    - TensorFlow\n",
    "    - Torch\n",
    "    - Darknet (Yolo)\n",
    "    - Models in ONNX format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load Deep Learning Model using OpenCV DNN\n",
    "    - `cv2.dnn.readNet(model, configration)` \n",
    "    - where :\n",
    "        - `model` :\n",
    "            - `*.caffemodel` (Caffe, http://caffe.berkeleyvision.org/)\n",
    "            - `*.pb` (TensorFlow, https://www.tensorflow.org/)\n",
    "            - `*.t7` | `*.net` (Torch, http://torch.ch/)\n",
    "            - `*.weights` (Darknet, https://pjreddie.com/darknet/)\n",
    "        - `configuration` :\n",
    "            - `*.prototxt` (Caffe, http://caffe.berkeleyvision.org/)\n",
    "            - `*.pbtxt` (TensorFlow, https://www.tensorflow.org/)\n",
    "            - `*.cfg` (Darknet, https://pjreddie.com/darknet/)\n",
    "    - This function automatically detects an origin framework of trained model and calls an appropriate function such \n",
    "        - `cv2.dnn.readNetFromCaffe` \n",
    "        - `cv2.dnn.readNetFromTensorflow`\n",
    "        - `cv2.dnn.readNetFromTorch` \n",
    "        - `cv2.dnn.readNetFromDarknet`\n",
    "    - OpenCV DNN config file bisa ditemukan [disini](https://github.com/opencv/opencv_extra/tree/4.x/testdata/dnn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Using Tensorflow Model\n",
    "- Load Model **Tensorflow SSD MobileNet v2**\n",
    "    - Download model `SSD MobileNet v2` dari [ssd_mobilenet_v2_coco_2018_03_29.tar.gz](http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz)\n",
    "    - Ekstrak file `.tar.gz`, \n",
    "    - Lalu ekstrak kembali file `.tar` yang ada di dalam folder hasil ekstrak sebelumnya,\n",
    "    - Masuk ke folder `saved_model/` lalu rename file `frozen_inference_graph.pb` ke `ssd_mobilenet_v2_coco_2018_03_29.pb`,\n",
    "    - Lalu download juga [ssd_mobilenet_v2_coco_2018_03_29.pbtxt](https://raw.githubusercontent.com/opencv/opencv_extra/4.x/testdata/dnn/ssd_mobilenet_v2_coco_2018_03_29.pbtxt),\n",
    "    - Setelahnya masukan kedua file tersebut ke folder `/Pertemuan 3/model/`<br><br>\n",
    "    \n",
    "- Model `SSD MobileNet v2` di training dengan `COCO Dataset` yang terdiri dari `80 class names` dalam `90 class index`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load COCO class names form `coco.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['background', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'unknown', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'unknown', 'backpack', 'umbrella', 'unknown', 'unknown', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'unknown', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'unknown', 'dining table', 'unknown', 'unknown', 'toilet', 'unknown', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'unknown', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "import coco\n",
    "\n",
    "classNames = coco.load_coco_class_names_tf()\n",
    "\n",
    "print(classNames)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load `SSD MobileNet v2` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"model/ssd_mobilenet_v2_coco_2018_03_29.pb\"\n",
    "config = \"model/ssd_mobilenet_v2_coco_2018_03_29.pbtxt\"\n",
    "net = cv2.dnn.readNet(model, config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Set OpenCV DNN Backend and Target via `.setPreferableBackend()` and `.setPreferableTarget()`<br><br>\n",
    "\n",
    "- Backend available option for OpenCV 4.5.3,\n",
    "    - `cv2.dnn.DNN_BACKEND_DEFAULT`\n",
    "    - `cv2.dnn.DNN_BACKEND_HALIDE`\n",
    "    - `cv2.dnn.DNN_BACKEND_INFERENCE_ENGINE`\n",
    "    - `cv2.dnn.DNN_BACKEND_OPENCV`\n",
    "    - `cv2.dnn.DNN_BACKEND_VKCOM`\n",
    "    - `cv2.dnn.DNN_BACKEND_CUDA`<br><br>\n",
    "\n",
    "- Target available option for OpenCV 4.5.3,\n",
    "    - `cv2.dnn.DNN_TARGET_CPU`\n",
    "    - `cv2.dnn.DNN_TARGET_OPENCL`\n",
    "    - `cv2.dnn.DNN_TARGET_OPENCL_FP16`\n",
    "    - `cv2.dnn.DNN_TARGET_MYRIAD`\n",
    "    - `cv2.dnn.DNN_TARGET_VULKAN`\n",
    "    - `cv2.dnn.DNN_TARGET_FPGA`\n",
    "    - `cv2.dnn.DNN_TARGET_CUDA`\n",
    "    - `cv2.dnn.DNN_TARGET_CUDA_FP16`\n",
    "    - `cv2.dnn.DNN_TARGET_HDDL`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since Plain Raspberry Pi 3 or 4 only Support Backend `cv2.dnn.DNN_BACKEND_OPENCV` and Target `cv2.dnn.DNN_TARGET_CPU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- define `layerOutput` by calling `.getUnconnectedOutLayersNames()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "layerOutput = net.getUnconnectedOutLayersNames()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"image1.jpg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert `Image data` to `Blob` via  `cv2.dnn.blobFromImage()`\n",
    "    - `cv2.dnn.blobFromImage(img, scalefactor=1.0, output_size, mean_channel, swapRB=false, crop=false, ddepth=cv2.CV_32F)`\n",
    "        - `image`\tinput image (with 1-, 3- or 4-channels).\n",
    "        - `size`\tspatial size for output image\n",
    "        - `mean`\tscalar with mean values which are subtracted from channels. Values are intended to be in (mean-R, mean-G, mean-B) order if image has BGR ordering and swapRB is true.\n",
    "        - `scalefactor`\tmultiplier for image values.\n",
    "        - `swapRB`\tflag which indicates that swap first and last channels in 3-channel image is necessary.\n",
    "        - `crop`\tflag which indicates whether image will be cropped after resize or not\n",
    "        - `ddepth`\tDepth of output blob. Choose cv2.CV_32F or cv2.CV_8U."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_h, resize_w = 300, 300 \n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1.0, (resize_w, resize_h), (0, 0, 0), swapRB=True, crop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Set blob to input network using `.setInput()` on `net` object\n",
    "- Do forward pass and get output using `.forward()` on `net` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.setInput(blob)\n",
    "output = net.forward(layerOutput)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Postprocessing detection result via `utils.py`\n",
    "    - Apply [NMS Box](https://learnopencv.com/tag/cv-dnn-nmsboxes/)\n",
    "    - Draw Detection Box\n",
    "    - use `.postprocessTensorflow()` for Tensorflow Model\n",
    "    - use `.postprocessYolo()` for Yolo Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils \n",
    "\n",
    "utility = utils.Utils()\n",
    "\n",
    "img = utility.postprocessTensorflow(output, img, classNames, font_size=0.8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"detection result\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Using Darknet Model\n",
    "- Load Model **Yolo v3 Tiny**\n",
    "    - Download model [yolov3-tiny.weights](https://pjreddie.com/media/files/yolov3-tiny.weights)\n",
    "    - Lalu download juga config [yolov3-tiny.cfg](https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3-tiny.cfg),\n",
    "    - Setelahnya masukan kedua file tersebut ke folder `/Pertemuan 3/model/`<br><br>\n",
    "    \n",
    "- Model `Yolo v3 Tiny` di training dengan `COCO Dataset` yang terdiri dari `80 class names` dalam `90 class index`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load coco class Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "import coco\n",
    "\n",
    "classNames = coco.load_coco_class_names_yolo()\n",
    "\n",
    "print(classNames)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load yolo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"model/yolov3-tiny.weights\"\n",
    "config = \"model/yolov3-tiny.cfg\"\n",
    "net = cv2.dnn.readNet(model, config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- setup opencv dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layerOutput = net.getUnconnectedOutLayersNames()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load image and conver to blob with `scaleFactor=1/255.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"image1.jpg\")\n",
    "\n",
    "resize_h, resize_w = 416, 416 \n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1/255.0, (resize_w, resize_h), (0, 0, 0), swapRB=True, crop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- do a forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.setInput(blob)\n",
    "output = net.forward(layerOutput)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Postprocessing detection result via `utils.py`\n",
    "    - Apply [NMS Box](https://learnopencv.com/tag/cv-dnn-nmsboxes/)\n",
    "    - Draw Detection Box\n",
    "    - use `.postprocessTensorflow()` for Tensorflow Model\n",
    "    - use `.postprocessYolo()` for Yolo Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils \n",
    "\n",
    "utility = utils.Utils()\n",
    "\n",
    "img = utility.postprocessYolo(output, img, classNames, font_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"detection result\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
